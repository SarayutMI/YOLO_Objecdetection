{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6V3kYFW9Ov5o"
   },
   "source": [
    "# Step 1 clone github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4844,
     "status": "ok",
     "timestamp": 1740087827087,
     "user": {
      "displayName": "Sarayut Meepanya",
      "userId": "17048776404462217560"
     },
     "user_tz": -420
    },
    "id": "JaqjiF2cNMPc",
    "outputId": "6f06ac1b-9bb4-438a-9d74-6c287cdfdc2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLO_Objecdetection'...\n",
      "remote: Enumerating objects: 54, done.\u001b[K\n",
      "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 54 (delta 0), reused 0 (delta 0), pack-reused 52 (from 1)\u001b[K\n",
      "Receiving objects: 100% (54/54), 107.61 MiB | 36.99 MiB/s, done.\n",
      "Resolving deltas: 100% (5/5), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SarayutMI/YOLO_Objecdetection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uirOEyU6O3aV"
   },
   "source": [
    "# Step2 install Env ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125812,
     "status": "ok",
     "timestamp": 1740087954152,
     "user": {
      "displayName": "Sarayut Meepanya",
      "userId": "17048776404462217560"
     },
     "user_tz": -420
    },
    "id": "3N6Ehr4QO2-v",
    "outputId": "444a69b0-2bdd-4357-f8ee-c1dcc37e3181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.78-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.78-py3-none-any.whl (921 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m921.5/921.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.78 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcYj-PJoPFXz"
   },
   "source": [
    "# Step 3 Import Libary and **Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1740087966095,
     "user": {
      "displayName": "Sarayut Meepanya",
      "userId": "17048776404462217560"
     },
     "user_tz": -420
    },
    "id": "VK4yzIVuPE3A"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    h, w, _ = image.shape\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # Denormalize the coordinates.\n",
    "        xmin = int(x1*w)\n",
    "        ymin = int(y1*h)\n",
    "        xmax = int(x2*w)\n",
    "        ymax = int(y2*h)\n",
    "\n",
    "        thickness = max(2, int(w/275))\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (xmin, ymin), (xmax, ymax),\n",
    "            color=(0, 0, 255),\n",
    "            thickness=thickness\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_paths, label_paths, num_samples):\n",
    "    all_images = []\n",
    "    all_images.extend(glob.glob(image_paths+'/*.jpg'))\n",
    "    all_images.extend(glob.glob(image_paths+'/*.JPG'))\n",
    "\n",
    "    all_images.sort()\n",
    "\n",
    "    num_images = len(all_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        j = random.randint(0,num_images-1)\n",
    "        image_name = all_images[j]\n",
    "        image_name = '.'.join(image_name.split(os.path.sep)[-1].split('.')[:-1])\n",
    "        image = cv2.imread(all_images[j])\n",
    "        with open(os.path.join(label_paths, image_name+'.txt'), 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label = label_line[0]\n",
    "                bbox_string = label_line[2:]\n",
    "                x_c, y_c, w, h = bbox_string.split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(result_image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9uMEVFTpJB"
   },
   "source": [
    "# Step 4 Prediction Model [ Folder Image All Class ] + Check Distace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1b6sw-x81C2bdKhz7bhNmthFYHObtyNDK"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21148,
     "status": "ok",
     "timestamp": 1740088034777,
     "user": {
      "displayName": "Sarayut Meepanya",
      "userId": "17048776404462217560"
     },
     "user_tz": -420
    },
    "id": "dEprGI-UTxuw",
    "outputId": "4341669b-f05e-4307-b755-d303c94fdd78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# โหลดโมเดลที่เทรนเสร็จแล้ว\n",
    "model = YOLO(\"/content/YOLO_Objecdetection/yolov8n_v8_50e4/weights/best.pt\")\n",
    "\n",
    "# โฟลเดอร์ที่เก็บภาพ\n",
    "input_folder = \"/content/YOLO_Objecdetection/inputimage\"\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# ฟังก์ชันคำนวณระยะห่าง\n",
    "def calculate_distance(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    a1, b1, a2, b2 = box2\n",
    "    center1 = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    center2 = ((a1 + a2) / 2, (b1 + b2) / 2)\n",
    "    return np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "\n",
    "# ระยะที่ถือว่า \"ใกล้\"\n",
    "THRESHOLD_DISTANCE = 170\n",
    "\n",
    "# วนลูปประมวลผลภาพทั้งหมด\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(input_folder, img_file)\n",
    "    results = model.predict(img_path, conf=0.25)\n",
    "\n",
    "    for result in results:\n",
    "        img = cv2.imread(img_path)\n",
    "        boxes = result.boxes\n",
    "\n",
    "        # แยกข้อมูล class ต่างๆ\n",
    "        persons = []\n",
    "        objects = {\"brush\": [], \"bucket\": [], \"cigarette\": [], \"smoke\": [], \"roller\": []}\n",
    "\n",
    "        for box in boxes:\n",
    "            xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            class_id = int(box.cls[0].cpu().numpy())\n",
    "            conf = box.conf[0].cpu().numpy()\n",
    "            class_name = model.names[class_id]\n",
    "\n",
    "            if class_name == \"person\":\n",
    "                persons.append(xyxy)\n",
    "            elif class_name in objects:\n",
    "                objects[class_name].append(xyxy)\n",
    "\n",
    "            # วาดกรอบทุก class\n",
    "            label = f\"{class_name} {conf:.2f}\"\n",
    "            cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 255, 0), 2)\n",
    "            cv2.putText(img, label, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # ตรวจสอบระยะห่างระหว่าง \"person\" กับวัตถุ\n",
    "        for px1, py1, px2, py2 in persons:\n",
    "            for obj_class, object_list in objects.items():\n",
    "                for bx1, by1, bx2, by2 in object_list:\n",
    "                    distance = calculate_distance((px1, py1, px2, py2), (bx1, by1, bx2, by2))\n",
    "\n",
    "                    # พิมพ์ระยะห่าง\n",
    "                    print(f\"Distance between person and {obj_class}: {distance:.2f} pixels\")\n",
    "\n",
    "                    if distance < THRESHOLD_DISTANCE:\n",
    "                        cv2.rectangle(img, (px1, py1), (px2, py2), (255, 0, 0), 2)  # วาดกรอบสีน้ำเงิน\n",
    "                        cv2.putText(img, f\"Near {obj_class}\", (px1, py1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # แสดงภาพใน Google Colab\n",
    "        cv2_imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUVYgBXEP0pm"
   },
   "source": [
    "# Step 4 Prediction Model [ Folder Image ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1v7WzXYhwsaepLAlsUZ_9OnGIPNh7SwgR"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15844,
     "status": "ok",
     "timestamp": 1740088191579,
     "user": {
      "displayName": "Sarayut Meepanya",
      "userId": "17048776404462217560"
     },
     "user_tz": -420
    },
    "id": "3xpxj32JPRi5",
    "outputId": "9a869ccb-83bf-410b-88fa-fffbbcb08154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# โหลดโมเดลที่เทรนไว้\n",
    "model = YOLO(\"/content/YOLO_Objecdetection/yolov8n_v8_50e4/weights/best.pt\")\n",
    "conf_threshold = 0.8  # ค่าความมั่นใจที่ใช้สำหรับกรองผลทำนาย\n",
    "\n",
    "# ตั้งค่าโฟลเดอร์ที่มีภาพ\n",
    "input_folder = \"/content/YOLO_Objecdetection/inputimage\"\n",
    "\n",
    "# อ่านไฟล์ทั้งหมดในโฟลเดอร์\n",
    "for filename in os.listdir(input_folder):\n",
    "    image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    # ตรวจสอบว่าไฟล์เป็นภาพ\n",
    "    if image_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # อ่านภาพ\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # ตรวจสอบว่าภาพถูกโหลดหรือไม่\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {filename}.\")\n",
    "            continue\n",
    "\n",
    "        # รันการตรวจจับ\n",
    "        results = model(image)\n",
    "\n",
    "        # อ่านผลลัพธ์\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy  # (x1, y1, x2, y2)\n",
    "            labels = result.boxes.cls  # Class Index\n",
    "\n",
    "            persons = []\n",
    "            objects = {\"brush\": [], \"bucket\": [], \"roller\": [], \"cigarette\": [], \"smoke\": []}\n",
    "\n",
    "            # แยกข้อมูล class ต่างๆ\n",
    "            for i, label in enumerate(labels):\n",
    "                x1, y1, x2, y2 = map(int, boxes[i])\n",
    "                class_name = model.names[int(label)]\n",
    "\n",
    "                if class_name == \"person\":\n",
    "                    persons.append((x1, y1, x2, y2))  # เก็บพิกัดบุคคล\n",
    "                elif class_name in objects:\n",
    "                    objects[class_name].append((x1, y1, x2, y2))\n",
    "\n",
    "            # ตรวจจับการกระทำของ \"person\"\n",
    "            for px1, py1, px2, py2 in persons:\n",
    "                is_painting = False\n",
    "                is_smoking = False\n",
    "\n",
    "                # เช็คว่าพบ \"brush\" หรือ \"bucket\" หรือ \"roller\" ใกล้กับ \"person\"\n",
    "                for bx1, by1, bx2, by2 in objects[\"brush\"] + objects[\"bucket\"] + objects[\"roller\"]:\n",
    "                    if bx1 < px2 and bx2 > px1 and by1 < py2 and by2 > py1:\n",
    "                        is_painting = True\n",
    "                        break  # เจออันใดอันหนึ่งก็พอ\n",
    "\n",
    "                # เช็คว่าพบ \"cigarette\" หรือ \"smoke\" ใกล้กับ \"person\"\n",
    "                for cx1, cy1, cx2, cy2 in objects[\"cigarette\"] + objects[\"smoke\"]:\n",
    "                    if cx1 < px2 and cx2 > px1 and cy1 < py2 and cy2 > py1:\n",
    "                        is_smoking = True\n",
    "                        break  # เจออันใดอันหนึ่งก็พอ\n",
    "\n",
    "                # กำหนดการกระทำของบุคคล\n",
    "                if is_painting:\n",
    "                    action_label = \"Person Painting\"\n",
    "                    color = (0, 255, 0)  # สีเขียว\n",
    "                elif is_smoking:\n",
    "                    action_label = \"Person Smoking\"\n",
    "                    color = (0, 0, 255)  # สีแดง\n",
    "                else:\n",
    "                    action_label = \"Person NoAction\"\n",
    "                    color = (255, 0, 0)  # สีน้ำเงิน\n",
    "\n",
    "                # วาดกรอบที่บุคคล (person)\n",
    "                cv2.rectangle(image, (px1, py1), (px2, py2), color, 2)\n",
    "                # วาดข้อความ\n",
    "                cv2.putText(image, action_label, (px1, py1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # แสดงผลภาพ\n",
    "        cv2_imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dIQdxa1PLGw"
   },
   "source": [
    "# Step 5 Prediction Model [ Folder Video ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIdvt1oyP9RP",
    "outputId": "5a48bf52-5a1c-46d2-8d26-a5a7a0733399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1443.9ms\n",
      "Speed: 17.8ms preprocess, 1443.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2099.2ms\n",
      "Speed: 22.7ms preprocess, 2099.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1644.3ms\n",
      "Speed: 28.5ms preprocess, 1644.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1338.4ms\n",
      "Speed: 15.2ms preprocess, 1338.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1299.2ms\n",
      "Speed: 15.3ms preprocess, 1299.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1463.6ms\n",
      "Speed: 14.8ms preprocess, 1463.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1399.1ms\n",
      "Speed: 15.4ms preprocess, 1399.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1366.9ms\n",
      "Speed: 14.7ms preprocess, 1366.9ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1308.6ms\n",
      "Speed: 15.5ms preprocess, 1308.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2201.6ms\n",
      "Speed: 15.7ms preprocess, 2201.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1695.0ms\n",
      "Speed: 27.3ms preprocess, 1695.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1417.4ms\n",
      "Speed: 14.9ms preprocess, 1417.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1384.7ms\n",
      "Speed: 18.4ms preprocess, 1384.7ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1360.6ms\n",
      "Speed: 15.3ms preprocess, 1360.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1382.6ms\n",
      "Speed: 15.3ms preprocess, 1382.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1407.9ms\n",
      "Speed: 16.2ms preprocess, 1407.9ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1396.1ms\n",
      "Speed: 24.6ms preprocess, 1396.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2110.3ms\n",
      "Speed: 30.6ms preprocess, 2110.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1581.8ms\n",
      "Speed: 33.4ms preprocess, 1581.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1346.6ms\n",
      "Speed: 16.3ms preprocess, 1346.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1318.4ms\n",
      "Speed: 15.1ms preprocess, 1318.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1733.3ms\n",
      "Speed: 15.9ms preprocess, 1733.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1395.3ms\n",
      "Speed: 17.6ms preprocess, 1395.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1299.1ms\n",
      "Speed: 15.1ms preprocess, 1299.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1647.8ms\n",
      "Speed: 15.2ms preprocess, 1647.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 2197.2ms\n",
      "Speed: 15.5ms preprocess, 2197.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1347.0ms\n",
      "Speed: 17.9ms preprocess, 1347.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1415.2ms\n",
      "Speed: 25.2ms preprocess, 1415.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1377.2ms\n",
      "Speed: 17.1ms preprocess, 1377.2ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1327.9ms\n",
      "Speed: 15.1ms preprocess, 1327.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1412.1ms\n",
      "Speed: 15.2ms preprocess, 1412.1ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1401.3ms\n",
      "Speed: 15.6ms preprocess, 1401.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1648.8ms\n",
      "Speed: 15.4ms preprocess, 1648.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2086.8ms\n",
      "Speed: 27.0ms preprocess, 2086.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1377.2ms\n",
      "Speed: 18.0ms preprocess, 1377.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1341.7ms\n",
      "Speed: 15.2ms preprocess, 1341.7ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1385.5ms\n",
      "Speed: 15.0ms preprocess, 1385.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1406.4ms\n",
      "Speed: 19.9ms preprocess, 1406.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1391.3ms\n",
      "Speed: 14.7ms preprocess, 1391.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1291.3ms\n",
      "Speed: 15.3ms preprocess, 1291.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1843.5ms\n",
      "Speed: 15.8ms preprocess, 1843.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1960.7ms\n",
      "Speed: 29.9ms preprocess, 1960.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1417.3ms\n",
      "Speed: 15.5ms preprocess, 1417.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1352.1ms\n",
      "Speed: 15.4ms preprocess, 1352.1ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1371.4ms\n",
      "Speed: 15.1ms preprocess, 1371.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1419.3ms\n",
      "Speed: 15.2ms preprocess, 1419.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1363.4ms\n",
      "Speed: 15.3ms preprocess, 1363.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1322.2ms\n",
      "Speed: 14.7ms preprocess, 1322.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 2949.9ms\n",
      "Speed: 15.1ms preprocess, 2949.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2525.7ms\n",
      "Speed: 47.0ms preprocess, 2525.7ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2033.6ms\n",
      "Speed: 15.8ms preprocess, 2033.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1314.1ms\n",
      "Speed: 14.8ms preprocess, 1314.1ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1386.3ms\n",
      "Speed: 15.4ms preprocess, 1386.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1440.5ms\n",
      "Speed: 14.8ms preprocess, 1440.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1380.4ms\n",
      "Speed: 23.1ms preprocess, 1380.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1638.3ms\n",
      "Speed: 15.0ms preprocess, 1638.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2084.5ms\n",
      "Speed: 16.2ms preprocess, 2084.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1424.6ms\n",
      "Speed: 14.9ms preprocess, 1424.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1339.2ms\n",
      "Speed: 20.8ms preprocess, 1339.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1366.3ms\n",
      "Speed: 15.1ms preprocess, 1366.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1371.4ms\n",
      "Speed: 15.8ms preprocess, 1371.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1406.6ms\n",
      "Speed: 15.8ms preprocess, 1406.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1347.1ms\n",
      "Speed: 15.5ms preprocess, 1347.1ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1669.0ms\n",
      "Speed: 14.8ms preprocess, 1669.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2014.7ms\n",
      "Speed: 31.5ms preprocess, 2014.7ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1422.4ms\n",
      "Speed: 17.3ms preprocess, 1422.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1363.4ms\n",
      "Speed: 16.9ms preprocess, 1363.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1427.2ms\n",
      "Speed: 16.2ms preprocess, 1427.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1386.9ms\n",
      "Speed: 15.9ms preprocess, 1386.9ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1321.1ms\n",
      "Speed: 15.3ms preprocess, 1321.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1428.6ms\n",
      "Speed: 17.8ms preprocess, 1428.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1954.0ms\n",
      "Speed: 16.1ms preprocess, 1954.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1839.5ms\n",
      "Speed: 32.7ms preprocess, 1839.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1350.0ms\n",
      "Speed: 17.1ms preprocess, 1350.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1428.7ms\n",
      "Speed: 15.4ms preprocess, 1428.7ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1345.3ms\n",
      "Speed: 15.4ms preprocess, 1345.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1354.6ms\n",
      "Speed: 15.3ms preprocess, 1354.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1402.8ms\n",
      "Speed: 15.7ms preprocess, 1402.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 3098.9ms\n",
      "Speed: 15.3ms preprocess, 3098.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1862.4ms\n",
      "Speed: 30.6ms preprocess, 1862.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1421.2ms\n",
      "Speed: 15.6ms preprocess, 1421.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2363.8ms\n",
      "Speed: 15.2ms preprocess, 2363.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1304.4ms\n",
      "Speed: 15.3ms preprocess, 1304.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1452.8ms\n",
      "Speed: 15.2ms preprocess, 1452.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1463.9ms\n",
      "Speed: 15.6ms preprocess, 1463.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1672.9ms\n",
      "Speed: 15.0ms preprocess, 1672.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2169.2ms\n",
      "Speed: 15.5ms preprocess, 2169.2ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1354.0ms\n",
      "Speed: 15.3ms preprocess, 1354.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1323.2ms\n",
      "Speed: 15.2ms preprocess, 1323.2ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1 smoke, 1471.8ms\n",
      "Speed: 16.9ms preprocess, 1471.8ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 3 cigarettes, 1 person, 1415.1ms\n",
      "Speed: 24.3ms preprocess, 1415.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1955.9ms\n",
      "Speed: 15.2ms preprocess, 1955.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 2052.3ms\n",
      "Speed: 25.6ms preprocess, 2052.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 2273.4ms\n",
      "Speed: 31.5ms preprocess, 2273.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1420.2ms\n",
      "Speed: 17.0ms preprocess, 1420.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1351.0ms\n",
      "Speed: 14.9ms preprocess, 1351.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1376.8ms\n",
      "Speed: 15.6ms preprocess, 1376.8ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 3 cigarettes, 1 person, 1416.5ms\n",
      "Speed: 15.7ms preprocess, 1416.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1322.5ms\n",
      "Speed: 14.7ms preprocess, 1322.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1296.4ms\n",
      "Speed: 15.3ms preprocess, 1296.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 2 cigarettes, 1 person, 1549.1ms\n",
      "Speed: 15.3ms preprocess, 1549.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 2169.3ms\n",
      "Speed: 19.8ms preprocess, 2169.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1416.5ms\n",
      "Speed: 29.1ms preprocess, 1416.5ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1404.2ms\n",
      "Speed: 16.6ms preprocess, 1404.2ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1377.9ms\n",
      "Speed: 15.6ms preprocess, 1377.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1297.5ms\n",
      "Speed: 15.9ms preprocess, 1297.5ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n",
      "0: 1280x704 1 cigarette, 1 person, 1416.1ms\n",
      "Speed: 15.3ms preprocess, 1416.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 704)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# โหลดโมเดล\n",
    "model = YOLO(\"/content/YOLO_Objecdetection/yolov8n_v8_50e4/weights/best.pt\")\n",
    "\n",
    "# ตั้งค่าพารามิเตอร์\n",
    "CONFIDENCE_THRESHOLD = 0.34\n",
    "THRESHOLD_DISTANCE = 850\n",
    "\n",
    "# กำหนดโฟลเดอร์ต้นทางและปลายทาง\n",
    "input_folder = \"/content/YOLO_Objecdetection/inputVideo\"\n",
    "output_folder = \"/content/YOLO_Objecdetection/output_inputVideo\"\n",
    "\n",
    "# สร้างโฟลเดอร์ปลายทางหากยังไม่มี\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ฟังก์ชันคำนวณระยะห่างระหว่างจุดศูนย์กลางของสองกล่อง\n",
    "def calculate_distance(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    a1, b1, a2, b2 = box2\n",
    "    center1 = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    center2 = ((a1 + a2) / 2, (b1 + b2) / 2)\n",
    "    return np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "\n",
    "# วนลูปผ่านวิดีโอทุกไฟล์ในโฟลเดอร์\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith((\".mp4\", \".mov\", \".avi\")):\n",
    "        video_path = os.path.join(input_folder, filename)\n",
    "        save_path = os.path.join(output_folder, filename.replace(\".MOV\", \".avi\").replace(\".mp4\", \".avi\"))\n",
    "\n",
    "        # เปิดไฟล์วิดีโอ\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # ตั้งค่า VideoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(save_path, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            results = model(frame)\n",
    "\n",
    "            for result in results:\n",
    "                boxes = result.boxes.xyxy\n",
    "                labels = result.boxes.cls\n",
    "                confidences = result.boxes.conf\n",
    "\n",
    "                persons = []\n",
    "                objects = {\"brush\": [], \"bucket\": [], \"roller\": [], \"cigarette\": [], \"smoke\": []}\n",
    "\n",
    "                for i, label in enumerate(labels):\n",
    "                    x1, y1, x2, y2 = map(int, boxes[i])\n",
    "                    conf = float(confidences[i])\n",
    "                    class_name = model.names[int(label)]\n",
    "\n",
    "                    if class_name == \"person\" and conf >= CONFIDENCE_THRESHOLD:\n",
    "                        persons.append((x1, y1, x2, y2))\n",
    "                    elif class_name in objects:\n",
    "                        objects[class_name].append((x1, y1, x2, y2))\n",
    "\n",
    "            for px1, py1, px2, py2 in persons:\n",
    "                is_painting = False\n",
    "                is_smoking = False\n",
    "\n",
    "                for obj_class, object_list in objects.items():\n",
    "                    for bx1, by1, bx2, by2 in object_list:\n",
    "                        distance = calculate_distance((px1, py1, px2, py2), (bx1, by1, bx2, by2))\n",
    "\n",
    "                        max_distance = 1300 if obj_class == \"roller\" else THRESHOLD_DISTANCE\n",
    "\n",
    "                        if distance < max_distance:\n",
    "                            if obj_class in [\"brush\", \"bucket\", \"roller\"]:\n",
    "                                is_painting = True\n",
    "                            elif obj_class in [\"cigarette\", \"smoke\"]:\n",
    "                                is_smoking = True\n",
    "\n",
    "                if is_painting:\n",
    "                    action_label = \"Person Painting\"\n",
    "                    color = (0, 255, 0)\n",
    "                elif is_smoking:\n",
    "                    action_label = \"Person Smoking\"\n",
    "                    color = (0, 0, 255)\n",
    "                else:\n",
    "                    action_label = \"Person NoAction\"\n",
    "                    color = (255, 0, 0)\n",
    "\n",
    "                cv2.rectangle(frame, (px1, py1), (px2, py2), color, 2)\n",
    "                cv2.putText(frame, action_label, (px1, py1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        # บีบอัดเป็น MP4\n",
    "        compressed_path = os.path.join(output_folder, filename.replace(\".MOV\", \".mp4\").replace(\".avi\", \".mp4\"))\n",
    "        os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
    "\n",
    "        print(f\"✅ ประมวลผลเสร็จ: {filename}\")\n",
    "\n",
    "print(\"🎉 เสร็จสิ้นการประมวลผลทุกไฟล์ในโฟลเดอร์!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q360hRsQEAt"
   },
   "source": [
    "# Step 5 Prediction Model [ Folder Video ]  Just 1 video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mm3UpOIHQMp5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# โหลดโมเดลที่เทรนไว้\n",
    "model = YOLO(\"/content/YOLO_Objecdetection/yolov8n_v8_50e4/weights/best.pt\")\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.34  # เพิ่มเงื่อนไขสำหรับ person\n",
    "THRESHOLD_DISTANCE = 850  # ปรับค่าระยะที่ถือว่าใกล้\n",
    "\n",
    "# กำหนดโฟลเดอร์ที่เก็บวิดีโอและไฟล์ผลลัพธ์\n",
    "video_folder = \"/content/YOLO_Objecdetection/inputOneVideo\"\n",
    "save_folder = \"/content/YOLO_Objecdetection/output_inputOneVideo\"\n",
    "\n",
    "# ตรวจสอบว่าโฟลเดอร์เซฟมีอยู่หรือไม่ ถ้าไม่มีให้สร้างขึ้นมา\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# ฟังก์ชันคำนวณระยะห่างระหว่างจุดศูนย์กลางของสองกล่อง\n",
    "def calculate_distance(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    a1, b1, a2, b2 = box2\n",
    "    center1 = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    center2 = ((a1 + a2) / 2, (b1 + b2) / 2)\n",
    "    return np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "\n",
    "# วนลูปอ่านไฟล์ในโฟลเดอร์\n",
    "for filename in os.listdir(video_folder):\n",
    "    if filename.endswith(\".MOV\") or filename.endswith(\".mp4\"):  # ตรวจสอบว่าเป็นไฟล์วิดีโอ\n",
    "        video_path = os.path.join(video_folder, filename)\n",
    "        save_path = os.path.join(save_folder, filename.replace(\".MOV\", \".avi\").replace(\".mp4\", \".avi\"))\n",
    "\n",
    "        # เปิดไฟล์วิดีโอ\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # รับค่าขนาดเฟรม (width, height)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # กำหนด codec และสร้าง VideoWriter สำหรับบันทึกวิดีโอที่ตรวจจับ\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(save_path, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # ถ้าไม่สามารถอ่านเฟรมได้ให้หยุด\n",
    "\n",
    "            # รันการตรวจจับวัตถุในแต่ละเฟรม\n",
    "            results = model(frame)\n",
    "\n",
    "            # อ่านผลลัพธ์\n",
    "            for result in results:\n",
    "                boxes = result.boxes.xyxy  # (x1, y1, x2, y2)\n",
    "                labels = result.boxes.cls  # Class Index\n",
    "                confidences = result.boxes.conf  # ค่าความมั่นใจ\n",
    "\n",
    "                persons = []\n",
    "                objects = {\"brush\": [], \"bucket\": [], \"roller\": [], \"cigarette\": [], \"smoke\": []}\n",
    "\n",
    "                # แยกข้อมูล class ต่างๆ\n",
    "                for i, label in enumerate(labels):\n",
    "                    x1, y1, x2, y2 = map(int, boxes[i])\n",
    "                    conf = float(confidences[i])  # แปลงค่า confidence เป็น float\n",
    "                    class_name = model.names[int(label)]\n",
    "\n",
    "                    if class_name == \"person\" and conf >= CONFIDENCE_THRESHOLD:\n",
    "                        persons.append((x1, y1, x2, y2))  # เก็บพิกัดบุคคล\n",
    "                    elif class_name in objects:\n",
    "                        objects[class_name].append((x1, y1, x2, y2))\n",
    "\n",
    "            # ตรวจจับการกระทำของ \"person\"\n",
    "            for px1, py1, px2, py2 in persons:\n",
    "                is_painting = False\n",
    "                is_smoking = False\n",
    "\n",
    "                # ตรวจสอบวัตถุที่อยู่ใกล้คน\n",
    "                for obj_class, object_list in objects.items():\n",
    "                    for bx1, by1, bx2, by2 in object_list:\n",
    "                        distance = calculate_distance((px1, py1, px2, py2), (bx1, by1, bx2, by2))\n",
    "\n",
    "                        # กำหนดระยะที่อนุญาตให้วัตถุอยู่ใกล้\n",
    "                        if obj_class == \"roller\":\n",
    "                            max_distance = 1300  # อนุญาตให้ roller อยู่ห่างได้ถึง 1300\n",
    "                        else:\n",
    "                            max_distance = THRESHOLD_DISTANCE  # ค่าเริ่มต้น 850\n",
    "\n",
    "                        if distance < max_distance:  # ถ้าอยู่ในระยะใกล้\n",
    "                            if obj_class in [\"brush\", \"bucket\", \"roller\"]:\n",
    "                                is_painting = True\n",
    "                            elif obj_class in [\"cigarette\", \"smoke\"]:\n",
    "                                is_smoking = True\n",
    "\n",
    "                # กำหนดการกระทำของบุคคล\n",
    "                if is_painting:\n",
    "                    action_label = \"Person Painting\"\n",
    "                    color = (0, 255, 0)  # สีเขียว\n",
    "                elif is_smoking:\n",
    "                    action_label = \"Person Smoking\"\n",
    "                    color = (0, 0, 255)  # สีแดง\n",
    "                else:\n",
    "                    action_label = \"Person NoAction\"\n",
    "                    color = (255, 0, 0)  # สีน้ำเงิน\n",
    "\n",
    "                # วาดกรอบที่บุคคล (person)\n",
    "                cv2.rectangle(frame, (px1, py1), (px2, py2), color, 2)\n",
    "                # วาดข้อความ\n",
    "                cv2.putText(frame, action_label, (px1, py1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # เขียนเฟรมที่ตรวจจับแล้วลงในวิดีโอ\n",
    "            out.write(frame)\n",
    "\n",
    "        # ปิดไฟล์วิดีโอและ VideoWriter\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        # แปลงเป็น mp4\n",
    "        compressed_path = save_path.replace(\".avi\", \".mp4\")\n",
    "        os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
    "\n",
    "        # อ่านไฟล์วิดีโอที่บีบอัดแล้ว\n",
    "        mp4 = open(compressed_path, 'rb').read()\n",
    "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "        # แสดงวิดีโอใน Jupyter Notebook / Colab\n",
    "        display(HTML(f\"\"\"\n",
    "        <video width=400 controls>\n",
    "              <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "        </video>\n",
    "        \"\"\"))\n",
    "\n",
    "print(\"✅ การประมวลผลวิดีโอเสร็จสมบูรณ์!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUfEUD+Bv6uXWzpcfeDC8Y",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
